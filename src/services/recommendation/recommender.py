"""Architecture recommendation service with AWS service selection logic."""

import os
from typing import List, Dict, Any, Optional
from uuid import UUID
from openai import OpenAI
from anthropic import Anthropic
from ..aws_knowledge.catalog import AWSServiceCatalog
from ..aws_knowledge.validator import AWSServiceValidator
from ...models.architecture_recommendation import ArchitectureRecommendation
from ...models.service import Service, ServiceType
from ...models.configuration import Configuration
from ...models.user_requirement import UserRequirement
from .well_architected import WellArchitectedChecker
from ...services.pricing.calculator import PricingCalculator


class ArchitectureRecommender:
    """Recommends AWS architectures based on user requirements."""

    def __init__(
        self,
        llm_provider: str = "openai",
        catalog: Optional[AWSServiceCatalog] = None,
        validator: Optional[AWSServiceValidator] = None,
    ):
        """Initialize architecture recommender.

        Args:
            llm_provider: LLM provider ('openai' or 'anthropic')
            catalog: AWS service catalog
            validator: AWS service validator
        """
        self.llm_provider = llm_provider
        self.catalog = catalog or AWSServiceCatalog()
        self.validator = validator or AWSServiceValidator(self.catalog)
        self.well_architected_checker = WellArchitectedChecker(validator, catalog)
        self.pricing_calculator = PricingCalculator()

        if llm_provider == "openai":
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("OPENAI_API_KEY environment variable not set")
            self.client = OpenAI(api_key=api_key)
            self.model = "gpt-4"
        elif llm_provider == "anthropic":
            api_key = os.getenv("ANTHROPIC_API_KEY")
            if not api_key:
                raise ValueError("ANTHROPIC_API_KEY environment variable not set")
            self.client = Anthropic(api_key=api_key)
            self.model = "claude-3-opus-20240229"
        else:
            raise ValueError(f"Unsupported LLM provider: {llm_provider}")

    async def recommend_architecture(
        self,
        requirements: List[UserRequirement],
        session_id: UUID,
        conversation_context: Optional[List[Dict[str, Any]]] = None,
    ) -> ArchitectureRecommendation:
        """Generate architecture recommendation based on requirements.

        Args:
            requirements: Extracted user requirements
            session_id: Conversation session ID
            conversation_context: Previous conversation context

        Returns:
            Architecture recommendation
        """
        # Build recommendation prompt
        prompt = self._build_recommendation_prompt(requirements, conversation_context)

        # Get service recommendations from LLM
        service_recommendations = await self._get_service_recommendations(prompt)

        # Create Service models
        services = []
        configurations = []
        for svc_data in service_recommendations.get("services", []):
            service = Service(
                recommendation_id=UUID("00000000-0000-0000-0000-000000000000"),  # Will be set later
                aws_service_name=svc_data["name"],
                service_type=ServiceType(svc_data.get("type", "other")),
                role=svc_data.get("role", ""),
                region=svc_data.get("region"),
            )
            services.append(service)

            # Create configurations for this service
            for config_data in svc_data.get("configurations", []):
                config = Configuration(
                    service_id=service.service_id,
                    config_type=config_data["type"],
                    config_value=config_data["value"],
                    config_details=config_data.get("details"),
                )
                configurations.append(config)

        # Check Well-Architected Framework alignment
        well_architected_alignment = self.well_architected_checker.check_alignment(
            services, configurations
        )

        # Create recommendation
        recommendation = ArchitectureRecommendation(
            session_id=session_id,
            services=services,
            configurations=configurations,
            diagram_data="",  # Will be generated by diagram service
            well_architected_alignment=well_architected_alignment,
            explanation=service_recommendations.get("explanation", ""),
        )

        # Update service recommendation_ids
        for service in services:
            service.recommendation_id = recommendation.recommendation_id

        return recommendation

    def _build_recommendation_prompt(
        self,
        requirements: List[UserRequirement],
        conversation_context: Optional[List[Dict[str, Any]]] = None,
    ) -> str:
        """Build prompt for architecture recommendation.

        Args:
            requirements: User requirements
            conversation_context: Conversation context

        Returns:
            Recommendation prompt
        """
        req_text = "\n".join([
            f"- {req.requirement_type.value}: {req.requirement_value}"
            for req in requirements
        ])

        # Get available services from catalog
        available_services = self.catalog.get_knowledge_base().get_all_services()
        services_text = "\n".join([
            f"- {svc.service_name}: {svc.description}"
            for svc in available_services[:20]  # Limit to first 20 for prompt size
        ])

        prompt = f"""你是一个AWS架构专家。根据用户需求推荐合适的AWS服务架构。

用户需求：
{req_text}

可用AWS服务（部分）：
{services_text}

请推荐合适的AWS服务架构，包括：
1. 服务列表（服务名称、类型、角色）
2. 每个服务的基本配置
3. 架构说明

请以JSON格式返回，格式如下：
{{
  "services": [
    {{
      "name": "EC2",
      "type": "compute",
      "role": "Web服务器",
      "region": "us-east-1",
      "configurations": [
        {{
          "type": "instance_type",
          "value": "t3.medium",
          "details": {{"vCPU": 2, "memory": "4GB"}}
        }}
      ]
    }}
  ],
  "explanation": "推荐使用EC2作为Web服务器，因为..."
}}
"""
        return prompt

    async def _get_service_recommendations(self, prompt: str) -> Dict[str, Any]:
        """Get service recommendations from LLM.

        Args:
            prompt: Recommendation prompt

        Returns:
            Service recommendations as dictionary
        """
        if self.llm_provider == "openai":
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "你是一个AWS架构推荐专家。只返回JSON格式的结果。"},
                    {"role": "user", "content": prompt},
                ],
                response_format={"type": "json_object"},
                temperature=0.5,
            )
            import json
            return json.loads(response.choices[0].message.content)
        elif self.llm_provider == "anthropic":
            response = self.client.messages.create(
                model=self.model,
                max_tokens=4000,
                messages=[
                    {"role": "user", "content": prompt},
                ],
            )
            import json
            content = response.content[0].text
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()
            return json.loads(content)
        else:
            raise ValueError(f"Unsupported LLM provider: {self.llm_provider}")

